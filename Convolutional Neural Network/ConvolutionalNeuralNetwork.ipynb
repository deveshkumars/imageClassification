{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devesh's Implementation of a Convolutional Neural Network to classify the MNIST Fashion Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 18:29:20.276016: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0-rc0\n"
     ]
    }
   ],
   "source": [
    "# Import statements\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train/255, x_test/255\n",
    "\n",
    "# Channels Dimms\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "# Batching and shuffling the dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(64, (3,3), activation=\"relu\")\n",
    "        self.maxPooling1 = MaxPooling2D((2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(64, activation=\"relu\")\n",
    "        self.d2 = Dense(10)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxPooling1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing and optimizer and loss function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# This is the metrics for loss and accuracy\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training = True only needed for dropout and other like layers\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)    \n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.04829656332731247, Accuracy: 98.22999572753906, Test Loss: 0.3939874768257141, Test Accuracy: 91.15999603271484\n",
      "Epoch 2, Loss: 0.042035289108753204, Accuracy: 98.50166320800781, Test Loss: 0.4211900234222412, Test Accuracy: 91.43000030517578\n",
      "Epoch 3, Loss: 0.03642602264881134, Accuracy: 98.69166564941406, Test Loss: 0.4842073619365692, Test Accuracy: 90.94999694824219\n",
      "Epoch 4, Loss: 0.03357263281941414, Accuracy: 98.83333587646484, Test Loss: 0.4705022871494293, Test Accuracy: 91.86000061035156\n",
      "Epoch 5, Loss: 0.030054103583097458, Accuracy: 98.92666625976562, Test Loss: 0.5027772188186646, Test Accuracy: 90.86000061035156\n",
      "Epoch 6, Loss: 0.03192662447690964, Accuracy: 98.88333129882812, Test Loss: 0.5155314207077026, Test Accuracy: 90.66000366210938\n",
      "Epoch 7, Loss: 0.025920387357473373, Accuracy: 99.11500549316406, Test Loss: 0.5607569217681885, Test Accuracy: 91.18000030517578\n",
      "Epoch 8, Loss: 0.022757308557629585, Accuracy: 99.25833129882812, Test Loss: 0.5367433428764343, Test Accuracy: 91.36000061035156\n",
      "Epoch 9, Loss: 0.021398428827524185, Accuracy: 99.27666473388672, Test Loss: 0.5749399662017822, Test Accuracy: 91.2699966430664\n",
      "Epoch 10, Loss: 0.022484401240944862, Accuracy: 99.25333404541016, Test Loss: 0.5598207116127014, Test Accuracy: 91.27999877929688\n",
      "Epoch 11, Loss: 0.02067677676677704, Accuracy: 99.20832824707031, Test Loss: 0.5903069376945496, Test Accuracy: 91.54999542236328\n",
      "Epoch 12, Loss: 0.016603417694568634, Accuracy: 99.3883285522461, Test Loss: 0.5959911346435547, Test Accuracy: 90.94999694824219\n",
      "Epoch 13, Loss: 0.019356444478034973, Accuracy: 99.30500030517578, Test Loss: 0.6023507118225098, Test Accuracy: 91.14999389648438\n",
      "Epoch 14, Loss: 0.015127348713576794, Accuracy: 99.49166870117188, Test Loss: 0.6224633455276489, Test Accuracy: 90.94000244140625\n",
      "Epoch 15, Loss: 0.016714045777916908, Accuracy: 99.43333435058594, Test Loss: 0.6411545276641846, Test Accuracy: 91.54999542236328\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset metrics at the start of each epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for images, labels, in train_ds:\n",
    "        train_step(images, labels)\n",
    "    \n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result()}, '\n",
    "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "        f'Test Loss: {test_loss.result()}, '\n",
    "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  multiple                 0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  692288    \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 693,578\n",
      "Trainable params: 693,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
